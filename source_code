import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import time

#Load CSV
file_path = 'datasets/7-uncleaned_email_data.csv'
df = pd.read_csv(file_path)

#Basic cleaning
df['Body'] = df['Body'].str.replace(r'http\S+', '', regex=True)
df['Body'] = df['Body'].str.replace(r' [^a-zA-Z\s]', '', regex=True)

# Expanded spam keyword detection for labeling
spam_keywords=['gift', 'offer', 'win', 'free', 'congratulations', 'winner', 'prize', 'claim', 'urgent']
df['Label'] = df['Subject'].fillna('').apply(lambda x: 1 if any(word in x.lower() for word in spam_keywords) else 0)

# Check label distribution
print("\nLabel distribution:")
print(df['Label'].value_counts())

texts = df['Body']
labels df['Label']

# ===================================
# 2. Modified Naive Bayes
# ===================================
print("\n== Modified Naive Bayes ===\n")

df['Body'] = df['Body].str.lower()

start_time = time.time()
vectorizer_mod = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=5000)
X_mod = vectorizer_mod.fit_transform(df['Body'])
end_time = time.time()
print(f"TF-IDF Vectorization Time (Modified): {end_time start_time:.4f} seconds")

start_time = time.time()
X_train_mod, X_test_mod, y_train_mod, y_test_mod = train_test_split(
    X_mod, labels, test_size=0.3, random_state=42, stratify=labels
)
end_time = time.time()
print(f"Train-Test Split Time (Modified): (end_time start_time:.4f) seconds")

start_time = time.time()
model_mod = MultinomialNB(alpha=0.7)
model_mod.fit(X_train_mod, y_train_mod)
end_time = time.time()
print(f"Training Time (Modified): {end_time - start_time:.4f} seconds")

start_time = time.time()
y_pred_mod = model_mod.predict(X_test_mod)
end_time = time.time()
print(f"Prediction Time (Modified): {end_time start_time:.4f} seconds")

accuracy_mod = accuracy_score(y_test_mod, y_pred_mod)
precision_mod = precision_score(y_test_mod, y_pred_mod, zero_division=1)
recall_mod recall_score(y_test_mod, y_pred_mod, zero_division=1)
f1_mod = f1_score(y_test_mod, y_pred_mod, zero_division=1)

print(f"Accuracy (Modified): {accuracy_mod:.4f}")
print(f"Precision (Modified): {precision_mod:.4f}")
print(f"Recall (Modified): {recall_mod:.4f}")
print(f"F1-Score (Modified): {f1_mod:.4f}")

# ====================================
# Comparison Summary
# ====================================
print("\n=== Comparison Summary ===")
print(f"{'Metric': <15} | {'Traditional': <10} | {'Modified': <10}")
print("-" * 40)

print(f"{'Accuracy': <15} | {accuracy_trad:.4f} | {accuracy_mod:.4f}")
print(f"{'Precision': <15} | {precision_trad:.4f} | (precision_mod:.4f}")
print(f"{'Recall' : <15} | {recall_trad:.4f} | {recall_mod:.4f}")
print(f"{'F1-Score': <15} | {fl_trad:.4f} | {f1_mod:.4f}")

# ====================================
# Confusion Matrix Plots
# ====================================
conf_matrix_trad = confusion_matrix(y_test_trad, y_pred_trad)
conf_matrix_mod = confusion_matrix(y_test_mod, y_pred_mod)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.heatmap(conf_matrix_trad, annot=True, fmt="d", cmap="Reds", xticklabels=["Not Spam", "Spam"],
yticklabels=["Not Spam", "Spam"])
plt.title("Traditional NB Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")

plt.subplot(1, 2, 2)
sns.heatmap(conf_matrix_mod, annot True, fmt="d", cmap="Greens", xticklabels=["Not Spam", "Spam"],
yticklabels=["Not Spam", "Spam"])
plt.title("Modified NB Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")

plt.tight_layout()
plt.show()
